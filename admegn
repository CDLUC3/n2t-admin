#!/bin/bash

# xxx do a system version of this, eg, EGNAPA_NOTIFY?
notify=n2tops@ucop.edu	# xxx backup, sysupdate, or other failure

# Add TMPDIR because of Berkeley DB performance with default "/"
export TMPDIR=~/backups

me=$( basename $0 )
function usage {

summary="
     $me warts
     $me binder_load Dbdir [ Dbdump_file ]
     $me bsync RemoteHost
     $me bstat [ Binder ... ]
     $me msync RemoteHost
       $me mdump [ -v ] [ Minter/nog.bdb ... ] [ > MinterStates ]
       $me mload [ -nv ] Dir [ < MinterStates ]
     (from backup) db_dump egg.bdb | ssh \$HOST '(cd \$dbdir; db_load egg.bdb)'
     $me cert_check [ restart | notify | '' ]
     $me validate_naans [ NAANsFile ]
     $me rcheck [ -v ]
     $me rstat IdPattern Logfile ...
     $me bootwatch [ -n ] Server [ WebServer ]
     $me sysupdate [ -y ]
     $me error_check [ -v ] [ email_notification_address ]
     $me patch_check [ email_notification_address ]
     $me pingwhen
     $me logdelete [ N ]
     $me logscrub Logfile ...
     $me logrename [ -n ] [ Dir ]
     $me backup
     $me backup_rotate"

	cat << EOT

SYNOPSIS                          ($0)
       $me - admin tool for Eggnog (essentially N2T)

USAGE $summary

DESCRIPTION
       NB: for the moment, this script assumes it is correct to always
       call Eggnog services with --service n2t.

       The $me tool performs various administrative tasks for the eggnog
       server database running under the "svu" service version that is
       currently in effect (or "cur" if none -- type "svu" for details).
       The -v option makes it more verbose for some forms.  A non-zero
       exit status indicates an error.

       Some important services are best done with other tools. For example,
       to migrate an entire binder to a new system, change into a quiescent
       ezid binder directory (one with the egg.bdb file in it), usually a
       recent backup copy. Then do something like

        \$ export TMPDIR=~/backups
        \$ rhost=n2t@ids-n2t2-prd.n2t.net
        \$ dbdir=sv/cur/apache2/binders/egg_n2t_prd_public.real_ezid_s_ezid
        \$ ssh \$rhost "( cd \$dbdir; rm log.* __db.* )"
        \$ db_dump egg.bdb | ssh \$rhost \\
	       "( cd \$dbdir; TMPDIR=~/backups db_load egg.bdb )"

       If you don't clean up the remote \$dbdir directory beforehand by
       removing egg.bdb and any __db.* and/or log.* files, bad things
       can happen when they interfere with the new environment. Also,
       bad things might happen if you're loading a new binder that will
       be used as it is appearing, so you might want to turn off apache.

XXX do a binder_backup_list command that lists the latest clean backup of each binder,

XXX do a binder_dump command that takes a timestamped clean binder backup,
creates a timestamped dump of it, suggests a next harvest: entry

       xxx this is awkward

       Also, you could have the dump file locally and call

        \$ admegn binder_load \$dbdir db_dump_file
       or
        \$ admegn binder_load \$dbdir < db_dump_file

       xxx it should restart apache afterwards, right? (why?)
           should it disable cron during that time too?

       XXX needed?
       The "warts" form takes the ~/warts/env.sh bash scripts and creates a
       corresponding ~/warts/env.yaml form of its settings (in YAML format).

       The "bsync" form updates the local host's binders with the binders'
       states found on the RemoteHost (eg, n2t@ids-n2t-prd-2a.n2t.net).
       NB: this command starts by reading the "next harvest" time (as a
       TEMPER timestamp) at the end of the remote ~/logs/iddumper_log file,
       reading transaction records from that time to the present, and ends by
       writing the next harvest time back to the end of the iddumper_log file.
       It goes to RemoteHost and runs "~/tlog/bsync2remote \$LocalHost".
       Running it every so often (eg, once a day or once an hour) keeps
       binders in sync. The more frequently it is run, the less work each
       iteration takes and the sooner it completes.

       The "bstat" form prints vital stats of each listed public Binder,
       or all public binders if no args are specified. Example:

            \$ $me bstat ezid

       The "msync" form updates the local host's minters with the minters'
       states found on the RemoteHost (eg, n2t@ids-n2t-prd-2a.n2t.net).
       It more or less follows the steps outlined below for mdump and mload.
       Running it every so often (eg, once a day or once an hour) keeps
       minters in sync. The more frequently it is run, the less work each
       iteration takes and the sooner it completes.

       The "mdump" form writes minter states in ANVL format to stdout.
       If no minters are specified, it looks for minters in a "minters"
       directory under the Apache server root.  If a Minter path is given,
       it should include the eggnog populator, eg, ezid, as in

            \$ for p in ezid oca yamz snac
            > do
            >     $me mdump minters/\$p/ark/?????/*/nog.bdb > m\$p
            > done
            \$ scp mezid moca myamz msnac n2t@ids-n2t2-prd.n2t.net:\$sa/

       The "mload" form reads a minter state file written by mdump from
       stdin and brings minters under directory Dir up to date, creating
       minters as need be. Compared with a brand new minter, bringing a
       recently updated minter up to date takes much less time. If -n is
       given, no states will be changed, but proposed changes will be
       reported. Dir should have populator subdirectories (ezid, oca,
       yamz, etc) as immediate descendants, for example,

            \$ for p in ezid oca yamz snac
            > do
            >     $me mload \$sa/minters < m\$p
            > done

       The "cert_check" form looks for an updated TLS/SSL certificate (from
       Let's Encrypt) and, if found, copies it into ~/warts/ssl/n2t.net after
       creating a backup copy (n2t.net.bak), and then takes the action
       "restart", "notify", or "" (none), ie, restarting Apache or emailing
       a notification. A "notify" action may be be useful in a production
       setting if you wish to do a manual "apache restart", but must be dealt
       with promptly because an unintended restart (eg, from a system reboot)
       will use the new cert. To rollback to the old cert, it suffices to
       rename the n2t.net.bak/ directory to n2t.net/ and do "apache restart".
       The "cert_check" form is usually called from crontab based on testing
       for a non-empty value returned by "\$(egg cfq new_cert_action)".

       The "validate_naans" form performs consistency and uniqueness checks
       on a NAANsFile containing ANVL-formatted NAAN records, returning a
       zero exit status if all checks pass.  The default file to check is
       $NAANsFile.

       The "rcheck" form tests that resolution is working correctly for a
       small number of well-known identifier/target pairs.  If resolution
       fails for any one of those pairs, an email is generated and the
       script exits with non-zero status.  The -v option makes it verbose.

       The "rstat" form summarizes resolution counts per month found in
       the Logfile arguments.  If IdPattern (a Perl regexp) is the empty
       string, all resolutions are counted, otherwise just matching
       resolutions are counted.  Logfiles may be in Eggnog transaction_log
       or (for older logs) or Apache access_log formats.
       xxx see "runoldrstat" script to scan over old actual data

       The "bootwatch" form is unusual in that it affects a REMOTE system.
       Use it to monitor an HTTP connection while trying to reboot the
       remote Server's OS (by connecting to it via a background ssh process
       -- best to set up password-less access).  It still monitors if it
       cannot reboot the Server, assuming you prefer to reboot it manually.
       If a WebServer host is specified, its HTTP connection is monitored
       instead of Server's, which is useful if WebServer is, for example,
       a load balancer in front of Server.  The monitoring process checks
       the external non-availability of the Server being rebooted by
       requesting the home page every second and printing a timestamp
       along with evidence of success or failure.  With the -n option, it
       does everything but reboot the remote system.

       The "sysupdate" form automatically updates the operating system
       of the current machine instance, but before doing so, warns of
       potentially de-stabilizing updates.  It buffers most output until
       finished, which may fool you into thinking it's not working.  For 
       optimistic or non-interactive operation, use -y to proceed past
       each question (continue? yes).(work in progress)

       The "error_check" form, usually started via crontab, checks for
       logged system errors (eg, /var/log/kernel) and creates a summary.
       It saves a summary of the prior run and, unless -v was given, only
       reports differences. If an email address is given, output is sent
       there instead of to stdout.

       The "patch_check" form, usually started via crontab, checks for
       critical OS updates. If there is an argument, it is taken to be an
       email address to which to send patch information, which is otherwise
       listed on stdout.

       The "pingwhen" form shows the last 15 times that the web server's
       home page was requested.  This is a crude way of helping you guess
       at what time a health check monitor is probing the server.  It can
       be useful for avoiding negative health checks when scheduling system
       updates, because sometimes they will make an instance appear to be
       down to load balancer users longer than it really is.

       The "logdelete" form, usually started via crontab, removes Apache log
       files older than the newest N access_log files (N=$logmax by default).

       The "logscrub" form anonymizes IP addresses in the given Apache
       access_log files by editing the files "in place", saving backup
       copies with a ".orig" suffix.  This doesn't work on error_log files,
       which may be retained to support business processes (see "logdelete").

       The "logrename" form, usually run once a day from cron, looks in Dir
       (defaults to ~/sv/cur/apache2/logs) for any filename of the form
       transaction_log.N and changes its name to transaction_log.YYYY.MM.DD
       based on the file's modtime.

       The "backup" form creates backups -- db_hotbackup for binders,
       admegn dumps for minters, and directory copies for shoulders.

       The "backup_rotate" form ages out surplus backups from dailies to
       weeklies to monthlies.  This and "backup" will likely be started
       via crontab.

EXAMPLES
       This command could be used to synchronize all the minters on the
       given remote system to the local system.

            \$ $me msync n2t@ids-n2t-prd-2a.n2t.net

       This command reboots a remote ssh host while monitoring its server.

	    \$ $me bootwatch ids-n2t2-prd.n2t.net n2t.net


SUMMARY $summary

EOT
}

# Usage: out_if exitcode [ error | stderr | any ] [ message ]
#
# Output message based on exitcode and condition:
#   error - on error print message on stdout for non-zero exitcode
#   stderr - on error print message on stderr for non-zero exitcode
#   any - always print message on stdout
#
function out_if {
	local ecode=$1 condition=$2 message=$3
	[[ "$ecode" ]] || ecode="no exit code for out_if?"
	[[ "$condition" ]] || condition=error
	[[ "$message" ]] || message="no message"
	local msg
	if [[ $ecode == 0 ]]		# if previous command had no error
	then
		msg="Success:"
	else
		msg="Error: exit code $ecode:"
	fi
	if [[ "$condition" == any ]]
	then
		echo "$msg" "$message"
		return
	elif [[ $ecode == 0 ]]		# else only print errors, so if none
	then
		return			# then return
	fi
	# If we get here, then $ecode detected an error.
	case "$condition" in
	error)
		echo "$msg" "$message"
		;;
	stderr)
		echo "$msg" "$message" 1>&2
		;;
	*)
		echo "$msg" "out_if: unrecognized condition ($condition):" \				"$message" 1>&2
		;;
	esac
	return
}

function mdump {

	if [[ $# -gt 0 ]]
	then
		minters=( $@ )
	else
		[[ "$aptop" ]] || {
			echo "Error: no apache server root found. You must" \
				"specify minter paths explicitly."
			exit 1
		}
		minters=( $apminters/*/ark/?????/*/nog.bdb )
		#minters=( $aptop/minters/*/ark/?????/*/nog.bdb )
	fi
	# First line of output identifies time and server.
	# xxx Probably should use xargs
	echo "# $( hostname -f ) | mdump | $( date +%Y.%m.%d_%H:%M:%S )"
	echo
	bdbkeys --get :/basecount :/oacounter \
		:/template :/original_template \
		:/type :/oklz :/germ :/atlast \
			-- ${minters[@]}
	echo "# ${#minters[@]} minters harvested"
}

function mload {

	# XXXXXX temporarily assume all ANVL records (which start ^::) are
	#        actually blank-line-separated paragraphs (hence -00)
	# typical entry looks like this:
	#    :: 13030/c7/nog.bdb
	#    %3a/oacounter: 276
	#    %3a/template: 13030/c7{eedeedk}
	Dir="$1"
	[[ "$Dir" ]] || {
		echo "Error: no Dir argument given"
		exit 1
	}
	[[ -d $Dir ]] || {
		echo "Error: given Dir argument ($Dir) doesn't exist"
		exit 1
	}

	# Temporarily put the perl script we'll use in the var $perl_mload,
	# using a "heredoc" (<<) so we don't have worry about quotes
	# surrounding it. Use the var right afterwards with perl -ne.
	#
	local perl_mload
	read -r -d '' perl_mload << 'EOT'

	# start embedded Perl program

	use strict;
	my $line = __LINE__;
	# look for next record beginning with exactly two colons "::"
	/^::($|[^:])/ or
		next;
	my ($header) = /^::\s*([^:][^\n]*)\n/m or
		print("Error line $line: bad header: $_\n"),
		next;
	my ($populator, $naan, $shdr) = $header =~
			m{([^/]+)/ark/(\w\w\w\w\w)/([^/]*)/nog\.bdb$} or
		print("Error line $line: header must be of form ",
				"Populator/ark/NAAN/Shoulder: $header\n"),
		next;
	my ($basecount) = m{^%3a/basecount:\s*(\d+)$}m or
		print("Error: no basecount in record $header\n"), next;
	my ($oacounter) = m{^%3a/oacounter:\s*(\d+)$}m or
		print("Error: no oacounter in record $header\n"), next;
	my $totalspings = $basecount + $oacounter;
	my ($template) = m{^%3a/template:\s*(.+)$}m or
		print("Error: no template in record $header\n"), next;
	my ($original_template) = m{^%3a/original_template:\s*(.+)$}m or
		print("Error: no original_template in record $header\n"), next;
	my ($type) = m{^%3a/type:\s*(.+)$}m or
		print("Error: no type in record $header\n"), next;
	#my ($oklz) = m{^%3a/oklz:\s*(.+)$}m or
	#	print("Error: no oklz in record $header\n"), next;
	#$oklz eq '<undef>' and		# XXXX interim code
	#	$oklz = '';

	my $oklz;
	($oklz) = m{^%3a/oklz:\s*(.+)$}m or
		$oklz = '';	# xxxzzz interim minter version upgrade

	my ($atlast) = m{^%3a/atlast:\s*(.+)$}m or
		print("Error: no atlast in record $header\n"), next;
	my ($germ) = m{^%3a/germ:\s*(.+)$}m or
		print("Error: no germ in record $header\n"), next;
	$germ and $type eq "seq" and
		print("Error: 'germ' defined for 'seq' minter in $header\n"),
		next;
	$ENV{ADMEGN_VERBOSE} and $original_template ne $template and
		print("Original template ($original_template) differs from ",
		  "current template ($template), probably due to expansion.\n");

	# These vars concern the location of the minter to be updated.
	#
	my $mbase = $ENV{MINTERS_TOP};
	my $shdrdir = "$mbase/$populator/ark/$naan/$shdr";
	my $nogfile = "$shdrdir/nog.bdb";

	# If we get here, we are done processing the ANVL entry and we
	# now need to figure out the minter file location of the minter
	# that we want to bring up to date with the entry.  We will
	# create a new minter if necessary.
	#
	# There is a special case when the minter template has any empty
	# shoulder string.  Mkminter is deficient (xxx) at handling this,
	# requiring the admin setting it up to have moved the minter into a
	# manually created shoulder directory, which is $shdr.  So the
	# remedy here is to create the new minter in a temporary directory
	# and move it to the same name as the manually created directory
	# name ($shdr).
	#
	my ($cmd, $out, $tbase, $empty_shdr);
	if (! -e $shdrdir) {		# create minter if it does not exist
		$tbase = "$mbase/$populator/ark";	# template base
		$empty_shdr = "";			# special case, for
		if ($original_template =~ m,(^{|/{),) {	# ... an empty shoulder
			$empty_shdr = $tbase;		# original $tbase
			$tbase .= "/tmp";		# temporary subdir
		}
		my $opts = ' ';
		$germ and $opts .= "--germ $germ ";
		$oklz and $opts .= "--oklz $oklz ";
		$cmd = "nog mkminter --type $type --atlast $atlast " .
			"$opts -p $tbase \"$original_template\"";
		#$cmd = "nog mkminter --type rand --atlast add3 " .
		#	"-p $tbase \"$original_template\"";
		print "$cmd\n";		# show command that will be exectuted
	}
	if (! -e $shdrdir and ! $ENV{ADMEGN_NO_EXEC}) {
		# create minter if it does not exist
		use File::Path qw(make_path);
		make_path($tbase);	# any error will come out in the wash
		$out = ` $cmd `;	# actual creation of the minter
		$out =~ m/^\n*$/s or
			print("Warning: nog mkminter returned: $out");
		if ($empty_shdr) {
			# Clean up special case, which normally would have
			# created a minter directly under the $naan directory,
			# but didn't in this case.  So we now rename it to
			# match the manually created directory name, ie,
			#     mv .../ark/tmp/$naan .../ark/$naan/$shdr
			#
			my $dstdir = "$empty_shdr/$naan/$shdr";
			print("... special handling for empty shoulder: ",
				"running make_path($tbase)\n");

			# The next two calls look weird but are necessary.
			# The first makes a full path to $dstdir and the
			# second removes just the leaf directory of $dstdir
			# so that the subsequent _directory_ rename will work.
			#
			make_path($dstdir) && rmdir($dstdir) or
				print("Error: skipping due to problem with ",
				  "make_path($dstdir) or rmdir($dstdir): $!\n"),
				next;
			rename("$tbase/$naan", $dstdir) or
				print("Error: skipping, as rename $tbase/$naan",
				  " -> $empty_shdr/$naan/$shdr failed: $!\n"),
				next;
			rmdir($tbase) or
				print("Warning: could not remove $tbase: $!\n");
		}
		-e $shdrdir or
			print("Error: mkminter failed -- skipping\n"),
			next;
	}

	# Now open the minter file to extract its "overall counter"
	# (for the current template) and "basecount" values, the sum of
	# which is the total number of spings minted.
	#
	use DB_File;
	my ($hash, $db, $curcnt, $n);
	$db = tie(%$hash, "DB_File", $nogfile, O_RDONLY, 0666, $DB_BTREE);
	$db or $ENV{ADMEGN_NO_EXEC} or
		print("Error: skipping, as tie failed on $nogfile: $!\n"),
		next;
	$n = $hash->{":/oacounter"};
	defined($n) or $n = 0;
	$curcnt = $n;
	$n = $hash->{":/basecount"};
	defined($n) or $n = 0;
	$curcnt += $n;
	#$curcnt = $hash->{":/oacounter"};
	#defined($curcnt) or
	#	$curcnt = 0;
	##	$curcnt = "<undef>";
	undef $db;
	untie %$hash;

	# Got the current value.  Bring it up to date if necessary.
	$curcnt =~ /^\d+$/ or
		print("Warning: skipping, as curcnt ($curcnt) not a number\n"),
		next;
	if ($curcnt < $totalspings) {
		my $diff = $totalspings - $curcnt;
		my $cmd = "nog -d $shdrdir mint $diff";
		print "$cmd\n";
		$ENV{ADMEGN_NO_EXEC} or
			$out = ` $cmd `;
		$ENV{ADMEGN_VERBOSE} and
			print "Counter for $populator/ark/$naan/$shdr would ",
				"now be up to date ($totalspings).\n";
	}
	elsif ($curcnt > $totalspings) {
		print "Warning: the current counter ($curcnt) is already ",
			"greater than the target value to update it to ",
			"($totalspings); leaving it untouched.\n";
	}
	else {
		$ENV{ADMEGN_VERBOSE} and
			print "No action on $populator/ark/$naan/$shdr since ",
				"counter ($curcnt) is up to date.\n";
	}
	# end embedded Perl program
EOT

	# Now call the script, just saved in $perl_mload, and pass in
	# values via environment variables.
	#
	env ADMEGN_NO_EXEC=$no_exec ADMEGN_VERBOSE=$verbose MINTERS_TOP=$Dir \
		perl -00 -wne "$perl_mload"
}

# load local binder from scratch using BDB dump on stdin

function binder_load {

	local dbdir=${1:-}
	local dbdump=${2:-}
	[[ ! "$dbdir" ]] && {
		echo "Error: no binder directory specified" 1>&2
		return 1
	}

	# $rbdr, $obdr, and $files are relative to $dbdir/..
	local rbdr=$( basename $dbdir )	# relative (no path) binder name
	local obdr=old/$rbdr		# old binder name (for backup)
	local files=(
		$obdr/{0=egg_1.00,0=pairtree_1.02,egg.rlog}
		$obdr/{egg_lock,egg_README,pairtree_root}
	)

	echo "ALERT: Disabling crontab. Remember to re-enable when done!"
	n2t cron stop

	if [[ -e $dbdir ]]
	then
		(cd $dbdir/..	# in subshell so we get original CWD later
			# old binder directories go here; should exist always
			mkdir -p old	# yy should move to n2t init step
			rm -fr $obdr	# only keep one single backup
			mv $rbdr $obdr
			mkdir $rbdr
			for f in "${files[@]}"
			do
				[[ ! -e $f ]] &&
					continue
				cp -pr $f $rbdr
			done
		)
	else
		mkdir $dbdir
		# yyy oops, what about our egg_README, etc. files?
	fi

	# NB: make sure TMPDIR env var is other than "/"
	local tail		# hopefully a timestamp from name in $dbdump
	if [[ "$dbdump" ]]	# recommended, since you can have a backup date
	then
		tail=$( basename $dbdump )	# hopefully timestamped name
		(cd $dbdir	# subshell so $dbdump path is from caller view
			date > FROM_BACKUP_$tail
			db_load egg.bdb
		) < $dbdump
	else
		tail="date_unknown"
		(cd $dbdir
			date > FROM_BACKUP_$tail
			db_load egg.bdb
		) # from STDIN
	fi
	[[ $( apache status ) =~ ^UP ]] && {
		echo "You should probably restart apache now."
	}
	cat << EOT

NB: To keep the loaded binder in sync with a remote binder, enter the TEMPER
(eg, 2020.07.30_02:37:01) timestamp of the snapshot in the last two-line entry
of the remote host's ~/logs/iddumper_log file. For this snapshot the timestamp
appears to be "$tail". Example last two lines:

# ======== start from date of full binder db_dump
# next harvest: 2020.08.04_02:37:01 /apps/n2t/sv/cur/apache2/logs/transaction_log

** If apache was running during loading, you should do "apache restart" now. **
EOT
}

# sync (update) local minters to catch up with source state of remote minters

function msync {

	local ruserhost=${1:-}
	[[ ! "$ruserhost" ]] && {
		echo "Error: no remote host specified" 1>&2
		return 1
	}
	echo "# ---- $me msync:" $( date '+%Y.%m.%d_%H:%M:%S' ) "----"
	ssh -n $ruserhost "(
		cd ~/sv/cur/apache2
		for p in ezid oca yamz snac
		do
			admegn mdump minters/\$p/ark/?????/*/nog.bdb
		done
	)" | admegn mload $apminters
}

# sync (update) local binders to catch up with source state of remote binders
# run this every 10 mins?

function bsync {

	local ruserhost=${1:-}
	[[ ! "$ruserhost" ]] && {
		echo "Error: no remote host specified" 1>&2
		return 1
	}
	localhost+=$( hostname -f )
	echo "# ---- $me bsync:" $( date '+%Y.%m.%d_%H:%M:%S' ) "----"
	echo "# running ssh -n $ruserhost 'tlog/bsync2remote n2t@$localhost'"
	ssh -n $ruserhost "tlog/bsync2remote n2t@$localhost"

	# XXX kludge -- make this work for all binders
	echo "#    after bsync EZID" "$( admegn bstat ezid | grep bindings )"
	echo "#    after bsync OCA " "$( admegn bstat oca  | grep bindings )"
	echo

}

# show vital stats

function bstat {

	[[ ${#*} -eq 0 ]] && {
		echo All binders -- not implemented
		exit 1
	}
	for b in $@
	do
		n2t $b mstat
	done
}

# NAANs file usually overridden during pfx validation
# xxx this function code is maintained in parallel between the N2T
#     admegn script and the "naans" script in the naan_registry repo

NAANsFile=

function validate_naans {

	[[ "$1" ]] &&
		NAANsFile="$1"

	perl - "$1" << 'EOT'

	# start embedded Perl program

	use 5.10.1;
	use strict;
	use warnings;

        use lib "/apps/n2t/local/lib";
        use NAAN;
        my $contact_info = 1;   # 1 means contact info should be present
	my $linenums = 1;	# 1 means print errors with line numbers
				# 0 for single entry validation
        my ($ok, $msg, $Rerrs) =	# prints errors and validation status
                NAAN::validate_naans($ARGV[0], $contact_info, $linenums);

	for my $e (@$Rerrs) {
	       say $e;
	}
	say $msg;
	exit(! $ok);

	# end embedded Perl program
EOT
	return
}

# xxx drop this old code soon
# these sources usually overridden during pfx validation
#
ShouldersFile=~/shoulders/master_shoulders.txt	# default
NAANsFile=~/naans/master_naans	# default

function xxxvalidate_naans {

	[[ "$1" ]] &&
		NAANsFile="$1"
	[[ "$2" ]] &&
		ShouldersFile="$2"
	perl - $NAANsFile $ShouldersFile << 'EOT'

	# start embedded Perl program

	use 5.10.1;
	use strict;
	use warnings;

	use Encode;		# to deal with unicode chars
	my $lcnt = 0;		# current line number (line count)
	my $ecnt = 0;		# current entry (count)
	my $errs = 0;		# error count
	my ($badseq1, $badseq2, %naans, %elems, %org_name, %org_acro);

	sub perr {
		print(STDERR "Entry starting line $lcnt: ",
			join('', @_), "\n");
		$errs++;
	}

	sub element_check { my( $k, $v )=@_;	# one key/value pair

		$k ||= '';
		$k or
			perr("missing key!"),
			return
		;
		$v ||= '';
		my ($year, $month, $day);
		$k =~ s/^\s*(.*?)\s*$/$1/;
		$v =~ s/^\s*(.*?)\s*$/$1/;
		++$elems{$k} > 1 and $k ne '!contact' and
			perr("multiple instances of element '$k'");
		if ($k eq 'naa') {
			$v and
				perr("element 'naa' should not have ",
					"a value");
			return;
		}
		$k and ! $v and
			perr("missing value for $k");
		# Type-specific checks, with $k known to be defined.
		#
		if ($k eq 'what') {		# duplicate check
			++$naans{$v} > 1 and
				perr("NAAN $v duplicated");
			$v =~ /^(\d\d\d\d\d)$/ or
				perr("malformed NAAN ($v): ",
					"should be NNNNN");
		}
		elsif ($k eq 'who') {
			my ($oname) = $v =~ m/^\s*(.*?)\s*\(=\)/ or
				perr("Malformed organization name: $v");
			my ($oacro) = $v =~ m/.*\(=\)\s*(.*?)$/ or
				perr("Malformed organization acronym: $v");
			++$org_name{$oname} > 1 and
				perr("Organization name $oname duplicated");
			++$org_acro{$oacro} > 1 and
				perr("Acronym $oacro duplicated");
		}
		elsif ($k eq 'when') {
			$v =~ /^(\d\d\d\d)\.(\d\d)\.(\d\d)$/ or
				perr("malformed date ($v): ",
					"should be NNNN.NN.NN"),
				return
			;
			($year, $month, $day) = ($1, $2, $3);
			$year and $year !~ /^(?:19|20)/ and
				perr("malformed year ($year): ",
					"should be 19NN or 20NN");
			$month and $month < 1 || $month > 12 and
				perr("malformed month ($month): ",
					"should be between 01 and 12");
			$day and $day < 1 || $day > 31 and
				perr("malformed day ($day): ",
					"should be between 01 and 31");
		}
		elsif ($k eq 'where') {
			$v =~ m|/$| and
				perr("URL should not end in /");
		}
	}

	my $naanfile = $ARGV[0];
	my $contact_info =		# peek to see if file is anonymized
		`grep -q '^\!contact' $naanfile && echo 1`;
	chop $contact_info;

	my ($c, $s, @uchars);
	open FH, "< $naanfile" or
		die();
	$/ = "";		# paragraph mode
	while (<FH>) {		# read file an entry (block) at a time
		$badseq1 = $badseq2 = 0;
		if ($. == 1 and ! /^erc:/m) {
			print STDERR
				"First entry missing \"erc:\" header\n";
			$errs++;
		}
		# if entry is first or is just all comment and blank lines
		# yyy . matches \n in -00 mode even without /s flag ?
		if ($. == 1 or /^(?:\s*#.*\n|\s*\n)*$/) {
			$lcnt += tr|\n||;	# counts \n chars
			next;
		}
		$ecnt++;

		# Need to validate either the full file (internal only,
		# with contact info) or anonymized file (no "!" fields).
		#
		$badseq1 = $. != 1 && ! m{	# not first entry and
			who:\s+.*?\s*\n		# not in proper order
			what:\s+.*?\s*\n
			when:\s+.*?\s*\n
			where:\s+.*?\s*\n
			how:\s+.*?\s*\n
		}xs;
		$contact_info and $badseq2 = $. != 1 &&
					/^!/m && ! m{	# if any "!" fields,
			how:\s+.*?\s*\n			# check their ordering
			!why:\s+.*?\s*\n
			!contact:\s+.*?\s*\n
		}xs;
		$badseq1 and
			perr("bad who-what-when-where-how-... sequence");
		$contact_info and $badseq2 and
			perr("bad how-why-contact... sequence");

		undef %elems;			# reinitialize
		# This loop will eat up the entry we're working on.  We
		# assume 1 elem per line (ie, no ANVL continuation lines).
		while (s/^(.*?)\n//) {	# process entry a line at a time
			$lcnt++;
			$s = $1;		# $s is line just removed
			$s =~ /^\s*#/ and	# skip comment lines
				next;
			$s =~ /^\s*$/ and	# skip blank lines
				next;
			# yyy don't yet do strict \t-only this version
			unless ($s =~ /^
				\s*(!?.[^:\n]*)\s*	# key
				:
				\s*([^\n]*)\s*		# value
				$/x) {
				#\s*?([^\n]*?)\s*?\n	# value
				print STDERR
					"Line $lcnt: missing colon\n";
				$errs++;
			}
			element_check($1, $2);
			$s =~ /\P{ascii}/ or	# if there's no non-ascii
				next;		# present, skip the rest

			# check for annoying non-ascii punctuation
			@uchars = split '', decode('utf8', $s);
			/\P{ascii}/ && /\p{Punctuation}/ && print(STDERR
				"Line $lcnt: non-ascii punctuation: ",
				encode('utf8', $_), "\n") && $errs++
							for (@uchars);
		}
	}
	close FH;

	# check that every NAAN mentioned in shoulders file is also in
	# the NAAN registry

	my $shfile = $ARGV[1];
	open FH, "sed -n 's,^:: ark:/*\\([0-9][0-9]*\\).*,\\1,p' $shfile |" or
		die();

	$/ = "\n";
	while (<FH>) {
		chop;
		! $naans{$_} and $errs++, print(STDERR
			"NAAN $_ from shoulders database missing from ",
				"NAAN registry\n");
	}
	close FH;

	if ($errs) {
		print("NOT OK - $naanfile: $ecnt entries, $errs errors\n");
		exit 1;
	}
	print("OK - $naanfile: $ecnt entries, $lcnt lines\n");
	exit;
	# end embedded Perl program
EOT
	return
}
# Doc for script /home/cdlinfra/ssl/script/cert_sync.sh at
# https://confluence.ucop.edu/display/CUG/SSL+Certificate+Management+Users+Guide

# Note: new certs are valid for 90 days.

function cert_check {

	local arg out cmd subject
	arg="${1:-}"
	[[ ! "$arg" ]] &&
		return 0		# no command means no-op, no action

	echo -n "+---- new cert check" $( date )	# no newline yet

	case $arg in
	restart)
		cmd="$HOME/init.d/apache restart"
		;;
	notify)
		subject='new cert: manual "apache restart" advised'
		cmd="mail -s '$subject' $notify"
		;;
	*)
		echo
		echo "error: $0 cert_check $arg: unknown command arg"
		return 1
		;;
	esac

	# /dev/null terminates any mail input
	out=$( /home/cdlinfra/ssl/script/cert_sync.sh \
		--outdir $HOME/warts/ssl/n2t.net \
		--restartcmd "$cmd" \
		"$( hostname -f )" \
		< /dev/null \
	)
	if [[ "$out" ]]
	then
		echo
		echo "$out"
	else
		echo ": no updates"
	fi
	return
}

function rcheck { 
	local i t itcnt got errcnt=0 msg=''
	local array i_t_pairs=(			# identifier/target pairs
	  'ark:/12345/fk1234'
		'https://cdlib.org/services'
	  'ark:/12345/fk1235'
		'https://en.wikipedia.org/wiki'
	  'ark:/12345/fk3'
		'https://www.google.com/search?q='
	)
	(( itcnt=(${#i_t_pairs[@]} / 2) ))

	# A real user ARK.  Don't test long-term because we don't know what
	# their commitment to it is, and we don't want to skew resolution
	# stats with lots of tests.  (2017.01.16)
	#  'ark:/87925/h1mw2f29'
	#	'http://www.ucd.ie/specialcollections'
	while [[ 1 ]]
	do
		[[ "${#i_t_pairs}" -eq 0 ]] &&		# if list now empty
			break				# we're done
		i="${i_t_pairs[0]}"			# save first pair
		t="${i_t_pairs[1]}"
		i_t_pairs=( ${i_t_pairs[@]:2} )		# drop first pair
		got=$( wegn locate "$i" |
			sed -ne 's/^Location: *//p' -e '/[Ee]rror/p' )
		[[ "$verbose" ]] && {
			echo For: "$i"
			echo Got: "$got"
		}
		grep -q "$t" <<< $got || {
			(( errcnt++ ))
			msg+="error: resolution failed for id $i
expected: $t
     got: $got
"
		}
	done

	[[ "$verbose" ]] && {
		msg+="rcheck: $itcnt resolution attempts, $errcnt failures"
	}
	[[ "$msg" ]] && {
		local subject="resolver health check report"
		[[ $errcnt -gt 0 ]] && {
			local sname=$( egg --home $aptop cfq shell_name )
			subject="CRITICAL: $sname: $errcnt resolver errors"
		}
		mail -s "$subject" $notify <<< "$msg"
	}
	[[ $errcnt -eq 0 ]] &&
		exit 0
	echo "$errcnt errors:
$msg"
	exit 1
}

function rstat {

	local IdPattern="$1"
	shift

# NB: the 4 files below present a sort of uniform format for access_log
# files with a simple record of resolution attempts.  The transaction_log
# introduced in July 2015 presents the best record going forward.
#
#      See "runoldrstat" for more.
#
#noidlog=$logdir/noid_logs/anonoid.access_log.060711_150630
#n2tprdlog=$logdir/n2tprd_logs/anon.n2tprd_access_log.2015.02.15-2015.07.02
#n2preprodlog=$logdir/n2preprod_logs/anon.access_log.to_2015Dec2
#awsAugDec2015log=$logdir/anon.alog2015.08.06-2015.12.30 # missing July?

	# Temporarily put the perl script we'll use in the var $perl_rstat,
	# using a "heredoc" (<<) so we don't have worry about quotes
	# surrounding it. Use the var right afterwards with perl -ne.
	#
	local perl_rstat
	read -r -d '' perl_rstat << 'EOT'

	# start embedded Perl program
	use strict;

	# XXXXXXXXXXXXXXXX use of __LINE__ all wrong in mload?
	#my $line = __LINE__;	#???? what does that mean?
	my %mnum = ( qw(
		Jan 01 Feb 02 Mar 03 Apr 04 May 05 Jun 06
		Jul 07 Aug 08 Sep 09 Oct 10 Nov 11 Dec 12
	) );
	my %h;		# hash for counting
	my ($key, $mon, $yyyy);
	my $pat = $ENV{ADMEGN_IDPAT};	# might be empty
	my $pat_orig = $pat;
	my $rpat;			# regex version of $pat
	$pat and $rpat = qr/$pat/;	# if non-empty, assume it's a regex
	my $alogformat;			# access_log format?
	my $curfile = '';		# current file name

	# xxx should handle more than one log file
	# xxx and different file formats in the same run
	while (<>) {
		if ($curfile ne $ARGV) {
			# Boolean $alogformat is true if we detect a file in
			# Apache access_log format (#2).  Otherwise assume
			# it's in Eggnog transaction_log format.  Below the
			# initial optional "- " drops the case when the XFF
			# (X-Forwarded-For) field doesn't show for some
			# reason (it's for when a load balancer made the
			# connection on behalf of someone else).  The XFF
			# field was introduced in our logs around Nov 2015.
			#
			$alogformat = m|^(?:- )?(?:\d{1,3}\.){3}\d{1,3}\ |;

			if (! $alogformat) {	# transaction_log format 1a/1b
				# the log format for "BEGIN resolve" lines
				# doesn't include ark:/ at the beginning
				# (I don't know why), but it might in the
				# future.  First remove any ark:/ that the
				# caller might have entered (makes sense),
				# then add the possibility of the future log
				# format recording ark:/.  Remember to re-init
				# for each file and that $pat may be empty.
				#
				$pat = $pat_orig;		# re-init
				$pat =~ s|^.*/?ark:/?||;	# if any
				$pat =~ s|^|BEGIN resolve (?:ark:/)?|;
				$rpat = qr/$pat/;
				#
				# We need this $pat in order to skip the
				# many lines of the transaction_log that
				# have nothing to do with resolution.
			}
		#print "xlog af=$alogformat pat=$pat\n";
		#exit;
			# xxx should set $pat to {\] "GET /\w{2,4}:"}
			#     to avoid obvious hack attempts
			$curfile = $ARGV;
		}
		$pat and ! /$rpat/ and	# skip lines we're not interested in
			next;
#1a #+n2t ids-n2t-prd-2a 2016.01.06_18:46:12.388755 yD4~0Oi05RG~dXl24fqjhQ BEGIN resolve 47881/m65b00q4 ac=*/*!!!ff=!!!ra=172.30.13.116!!!co=!!!re=!!!ua=Mozilla/5.0 (compatible; bingbot/2.0; +http://www.bing.com/bingbot.htm)
#1b #+jak jak-macbook 2015.12.15_17:21:03.884377 ~tlARpOj5RGiMwIO9vRdMw BEGIN resolve /eoi:10.5072/EOITEST ac=text/turtle!!!ff=!!!ra=::1!!!co=!!!re=!!!ua=Wget/1.15 (darwin13.1.0) +jak jak-macbook 2015.12.15_17:21:03.884574 ~tlARpOj5RGiMwIO9vRdMw END SUCCESS doi:10.5072/EOITEST -> redir303 http://crossref.org//mdata
#2 #12.34.56.78 - - [24/Sep/2012:23:58:04 -0700] "GET /ark:/47881/m6wd3xhz HTTP/1.0" 302 325
		# extract month and year from log line
		if ($alogformat) {
			m{ \[\d{1,2}/(\w{3})/(\d{4}):[\d: -]+\] } or
				print("Error: date not in DD/Mon/YYYY format in $_"),
				next;
			($mon, $yyyy) = ($1, $2);	# format Mon/YYYY
			$key = "$yyyy." . $mnum{$mon};	# convert to YYYY.MM
		}
		else {
			m{ (\d{4}\.\d\d)\.\d\d.\d\d:} or
				print("Error: no YYYY.MM.DD format in $_"),
				next;
			$key = $1;
		}
		# Hash keys are YYYY.MM, which sort nicely.
		$h{$key} ||= 0;		# initialize if need be
		$h{$key}++;		# increment counter for each hit
	}
	my %y;					# for yearly hash
	print "Resolution attempts",
		($pat ? " for $pat" : " (any)"), "\n";
	foreach $key (sort keys %h) {
		print("$key => $h{$key}\n");	# report monthly
		$key =~ m/^(\d\d\d\d)\./ or
			print("Error: key not in YYYY.MM form: $key\n"),
			next;
		$yyyy = $1;
		$y{$yyyy} ||= 0;
		$y{$yyyy} += $h{$key};
	}
	foreach $yyyy (sort keys %y) {
		print("$yyyy => $y{$yyyy}\n");
	}
	# end embedded Perl program
EOT

	# Now call the script, just saved in $perl_rstat, pass in values
	# via environment variables, and put file arguments on the end.
	#
	env ADMEGN_IDPAT=$IdPattern \
		perl -we "$perl_rstat" "$@"
}

function uptest {
	webserver=$1
	wget -T 1 -t 1 -q -O - $webserver | grep -i 'Name-to-Thing.*Resolver'
}

function bootwatch {

	local m s ws server webserver
	s=$1		# server might be URL
	ws=$2		# webserver might be URL
	[[ "$ws" ]] ||
		ws=$s	# default webserver same as server

	# convert any URL-ness to pure hostnames that we'll use
	   server=$( sed 's,https*://\([^/]*\)/*,\1,' <<< $s)
	webserver=$( sed 's,https*://\([^/]*\)/*,\1,' <<< $ws)

	up=$( uptest $webserver )
	[[ $no_exec ]] &&
		echo no_exec, but did run: uptest $webserver
	[[ "$up" ]] || {
		m="Server $webserver down already, or unreachable "
		m+="-- proceed anyway? [n] "
		read -t 30 -p "$m" || {
			echo "Read timeout or EOF"
			exit 1
		}
		[[ "${REPLY:-n}" =~ ^[Nn] ]] && {
			echo "OK, stopping."
			exit 1
		}
	}
	host=$( sed 's/:.*//' <<< $server)	# drop port number, if any
	if [[ $no_exec ]]
	then
		echo "no_exec, so didn't run:" \
			"ssh $host 'sleep 2; sudo /sbin/init 6' &"
		echo "use control-C to break out of uptest loop"
	else
		ssh $host 'sleep 2; sudo /sbin/init 6' &
	fi
	local up= was_down= t0= show= up_again=0 downtime=0
	while [[ $up_again -lt 2 ]]
	do
		up=$( uptest $webserver )
		if [[ "$up" ]]
		then
			if [[ $was_down ]]
			then
				echo ""		# so next echo won't overwrite
				was_down=
				up_again=1
			fi
			echo "    up" `date`
			[[ $up_again -gt 0 ]] &&
				let up_again++
		else
			if [[ $was_down ]]
			then
				downtime=$(( $( date +%s ) - $t0 ))
				show="$was_down $downtime seconds"
			else	# just went down, so record time in seconds as
				t0=$( date +%s )	# we'll do arithmetic
				was_down=$( date )	# human readable
				show=$was_down
			fi
			echo -ne "  down $show\r"
		fi
		sleep 1
	done
	[[ $no_exec ]] &&
		return
	m="$(date +%Y.%m.%d_%H:%M:%S) $webserver N2T down for $downtime seconds"
	[[ $downtime -gt 0 ]] && {
		echo "$m" >> ~/logs/rebootlog
		echo "$m"
	}
}

# Exit status of 1 means yum update was not run.
# Exit status of 0 means yum update was run.
# Exit status of 2 means yum update was run and kernel updates occurred
#    (this is used to detect when a system reboot is indicated)
function sysupdate {

	local makecache updates noise count
	makecache=$( yum makecache fast )		# update repo metadata 
	updates=$( yum check-update | grep -v '^Loaded plugins' )
	noise=$( egrep '^db|perl' <<< "$updates" )
	count=$( grep -c '.' <<< "$updates" )	# non-empty lines

	echo -n "+==== sysupdate start: "		# for log file
	date
	# xxx this $count is not accurate
	echo -n "$count updates pending"		# unfinished line
	if [[ "$yes" ]]
	then
		if [[ "$noise" ]]
		then
			echo ", including"
			echo "$noise"
		echo "# $( hostname -f ) | mdump | $( date +%Y.%m.%d_%H:%M:%S )"
			local h
			h=$( hostname -f )
			mail -s "WARNING: critical software updated on $h!" \
				$notify <<< "$noise"
		else
			echo ""
		fi
	elif [[ "$noise" ]]
	then
		echo ", including"
		echo "$noise"
		read -t 30 -p "Proceed? [y] " || {
			echo "Read timeout or EOF"
			exit 1
		}
		[[ "${REPLY:-y}" =~ ^[Yy] ]] || {
			echo "OK, not updating."
			exit 0
		}
	else
		echo ""				# finish that line
	fi

	if [[ $count -le 0 ]]
	then
		echo "Exiting - no updates to do."
		exit 0
	fi

	local dontask=
	if [[ "$yes" ]]
	then
		dontask=-y
	else
		read -t 30 -p "Approve updates? [y] " || {
			echo "Read timeout or EOF"
			exit 1
		}
		[[ "${REPLY:-y}" =~ ^[Yy] ]] || {
			echo "OK, not updating."
			exit 0
		}
		dontask=-y		# -y means "approve as if yes"
	fi

	# If we get here, do the update
	local msg
	msg=$( sudo yum $dontask update )

#	# AWS yum updates of mongod automatically enable mongod on reboot,
#	# which creates socket file owned by mongod that we can't remove
#	# without superuser powers. So make sure mongod is always disabled,
#	# after any system update.
#
#	ls -l /tmp/mongo*		# check permissions before intervention
#
#	sudo /usr/bin/systemctl stop mongod
#	sudo /usr/bin/systemctl disable mongod
#	sudo /usr/bin/systemctl status mongod
#
#	ls -l /tmp/mongo*		# check permissions after intervention

	echo "$msg"
	echo 'Restarting apache and running "n2t test"'
	~/init.d/apache restart || {
		echo "ERROR: apache restart failed"
		exit 1
	}
	n2t test || {
		echo 'WARNING: "n2t test" failed'
		# fall through because some test failures are benign
	}
	if [[ "$msg" =~ "kernel-" ]]
	then
		echo "+==== Kernel updates -- system reboot advised."
	else
		echo "+==== Kernel updates not detected --" \
			"system reboot advised anyway."
		# NB: experience has shown that updates without reboot
		# can disable critical infrastructure, such as crontab
	fi
	exit 2
	#exit 0
}

logmax=6
function logdelete {

	local N=$1
	[[ "$N" ]] ||
		N=$logmax
	[[ $N =~ ^[1-9][0-9]*$ ]] || {
		echo "Error: logdelete argument ($N) not a number"
		return 1
	}
	echo -n "+==== logdelete: "		# for log file
	date

	local logdir alogs elogs num_alogs num_excess
	logdir=~/sv/cur/apache2/logs
	cd $logdir || exit

	# We count on 'ls' sorting order and our filenaming convention:
	# access_log.YYYY.MM.DD.  The number of access_log files is key.
	#
	alogs=$(
		ls access_log.????.??.?? | sed 's/access_log\.//'
	)
	num_alogs=$( wc -l <<< "$alogs" )
	((num_excess=( $num_alogs - $N )))
	[[ $num_excess -lt 0 ]] && {
		echo "No ($num_excess) excess log files to delete."
		return 0
	}
	elogs=$( head -$num_excess <<< "$alogs" )
	for i in $elogs
	do
		# Assume that all log files have the same date stamp, and
		# delete any contemporaneous .nnon (non-anonymized) files.
		#
		echo Deleting:
		ls {access,error,rewrite}_log.${i}*
		rm -f {access,error,rewrite}_log.${i}{,.nnon}
	done
	return 0
}

function xxxclass {

	source ~/warts/env.sh
	local Host=${1:-$EGNAPA_HOST}
	[[ ! "$Host" ]] && {
		echo "error: EGNAPA_HOST ($EGNAPA_HOST) not set." 1>&2
		return 1
	}
	local newline=			# empty the first time through
	[[ "$Host" == 'list' ]] && {
		echo "$classfmt"
		for i in "${hostclass[@]}"
		do
			[[ "$i" =~ ^- ]] && {
				echo -ne "$newline${i/-/}: "
				continue
			}
			newline="\n"
			echo -n "$i "
		done
		echo			# final newline
		return 0
	}
	# if we get here, we're looking for the given host
	for i in "${hostclass[@]}"
	do
		[[ "$i" =~ ^- ]] && {
			class="${i/-/}"
			cname=
			continue
		}
		[[ ! "$cname" ]] &&
			cname="$i"
		[[ "$i" == "$Host" ]] && {
			echo "$class $cname"
			return 0
		}
	done
	echo "Host \"$Host\" not found.  Try \"$me class list\"."
	return 1
}

# Some common log directories: $aptop/logs, ~/.eggnog/logs 
# Filenames of the form transaction_log.N contain log intervals, the smaller
# the value of N, the younger it is, eg, youngest to oldest:
#    transaction_log
#    transaction_log.1
#    transaction_log.2
#    ...
#    transaction_log.999

function logrename {

	local dir=${1:-$aptop/logs}		# default
	local t=transaction_log
	local mtime suffix raw_ls
	local sorted=()

	cd $dir || {
		echo "Error: unable to cd to $dir" 1>&2
		return 1
	}
	( shopt -s extglob	# automatically restored when subshell exits
	raw_ls=$( ls $t.+([0-9]) 2>&1 ) || {
		echo "nothing to rename this time"
		return
	}
	sorted=( $( sort --reverse -n -t . -k 2 <<< "$raw_ls" ) )
	for f in ${sorted[@]}
	do
		suffix=
		# Damned incompatibility of "stat" between Mac and Linux
		mtime=$( stat -f %m $f 2>&1 ) && {	# try the Mac OS way
			suffix=$( date -r $mtime "+%Y.%m.%d" 2>&1 )
		}
		[[ ! "$suffix" ]] && {	# if it didn't work, try the Linux way
			suffix=$( date -r $f "+%Y.%m.%d" )
		}

		# Expect no such file, but don't clobber an existing file.
		# Input files are sorted so that lower numbered files are
		# appended after higher numbered (older) files. Reverse sort
		# on original suffix N puts newer log entries after older.

		[[ -f $t.$suffix ]] && {
			echo "Warning: rename will append to a" \
			"timestamped log file that already exists" 1>&2
		}
		if [[ "$no_exec" ]]
		then
			echo -E "- cat $f >> $t.$suffix; rm $f"
		else
			echo renaming $f to $t.$suffix
			cat $f >> $t.$suffix
			rm $f
		fi
	done
	)
}

function backup {

	local now
	now=$( date '+%Y.%m.%d_%H:%M:%S' )
	local src dst took
	local txnlog=~/sv/cur/apache2/logs/transaction_log.rlog

	echo ==== creating backups $(date) ====
	# make sure our base directories are set up; quell complaints
	mkdir -p ~/backups/{minters,shoulders,binders,prefixes}

	dst=~/backups/minters/$now
	echo Backing up minters to $dst.
	admegn mdump > $dst

	dst=~/backups/shoulders/$now
	echo Backing up shoulders and transaction_log to $dst.
	mkdir $dst
	#cp -Lpr ~/shoulders/* ~/sv/cur/apache2/logs/transaction_log.rlog $dst
	cp -Lpr ~/sv/cur/apache2/logs/transaction_log $dst
	# xxx ouch, these are big logs, getting backed up with shoulders
	[[ -e ~/naans ]] && {
		cp -Lpr ~/naans/{main_naans,candidate_naans,shoulder_registry} $dst >& /dev/null
	}
	# xxx not actually backing up shoulders

	dst=~/backups/prefixes/$now
	echo Backing up prefixes to $dst.
	mkdir -p $dst
	pfx backup $dst

	# old:
	#	local pfx_work=~/sv/cur/apache2/pfx_work
	#	local pfx_harvest=~/pfx_harvest
	#	cp -Lpr $pfx_work $pfx_harvest $dst

	echo Backing up binders.
	local binders bkubinders user
	binders=$( shopt -s nullglob; echo $apbinders/* )
	bkubinders=				# backed-up binders, pass 1

	for binder in $binders
	do
		b=$( basename $binder )
		user=$(
			cd $eggnog;
			perl -Mblib egg --all bpname $b | sed -ne 's/who: *//p'
		)
		# Look for reasons not to backup
		if [[ -e $apbinders/NOBACKUP ||		# skip all binders
		      -e $apbinders/$b/NOBACKUP ||	# skip this binder
		      $b =~ _test$ ||			# skip test binders
		      $b =~ _old$ ||			# skip old binders
		      ! -e $apbinders/$b/egg.bdb ]]	# random dir that has
		then					#    no actual binder
			continue
		fi

		# In order to be able to run egg against a backup binder,
		# and because of how egg requires long ugly binder names in
		# anticipation of flatter database-server-based binder access
		# (instead of tidy short names made unique by file hierarchy),
		# we need the long binder name to be the final path component
		# before the egg.bdb file. The awkward consequence is that the
		# binder names both the parent and a chile of the timestamped
		# backup directory.

		src=$apbinders/$b
		dst=~/backups/binders/$user/$now/$b
		#dst=~/backups/binders/$b/$now
		mkdir -p $dst
		echo Running: db_hotbackup -h $src -b $dst
		db_hotbackup -h $src -b $dst
		bkubinders+=" $dst"			# save backed-up binder
		#took=$( ( time db_hotbackup -h $src -b $dst ) 2>&1 )
		#echo " " $( sed -n s/real//p <<< "$took" )
	done

	echo Verifying binder backups.
	local msg
	#for binder in $binders
	for binder in $bkubinders
	do
		#[[ $b =~ _test$ || ! -e ~/binders/$b/egg.bdb ]] &&	# skip
		#[[ $b =~ _test$ || $b =~ _old$ ||	# skip these and dirs
		#    ! -e $apbinders/$b/egg.bdb ]] &&	# w.o. real binders
		#	continue
		#[[ $b =~ _test$ || ! -e $apbinders/$b/egg.bdb ]] &&	# skip
		#	continue	# if not a binder or not a real binder
		#dst=~/backups/binders/$b/$now

		b=$( basename $binder )
		echo Running: db_verify $binder/egg.bdb
		#dst=~/backups/binders/$b/$now/$b
		#echo Running: db_verify $dst/egg.bdb
		#msg=$( time db_verify $dst/egg.bdb 2>&1 ) || {
 		#msg=$( db_verify $dst/egg.bdb 2>&1 ) || {
 		msg=$( db_verify $binder/egg.bdb 2>&1 ) || {
			#echo "$msg" > $dst/VERIFY_FAILED
			echo "$msg" > $binder/VERIFY_FAILED
			echo "$b backup - NOT OK"
			echo "$msg"
			mail -s "$b binder backup (removed) failed db_verify" \
				$notify <<< "$msg"
			rm -fr $(dirname $binder)  # toss -- backup not useful
			#rm -fr $(dirname $dst)	# toss -- backup not useful
			continue		# don't fall through
		}

		# Generate a complete list of all its ids.
		#
# XXX make complete bindings count available
		echo "$b backup verified; now saving id list"
		#time egg --home $aptop -d $dst/egg.bdb list 0 \
		#	> $dst/VERIFY_LIST 2>&1
		time egg --home $aptop -d $binder/egg.bdb list 0 \
			> $binder/VERIFY_LIST 2>&1
	done

	return 0
}

# Usage:  surplus cmd src max dst
# Call with three args naming a cmd (move1 or remove), a src directory,
# an integer, max, defining the maximum number that you want to keep,
# and a directory, dst (usually ending in "weeklies" or "monthlies"),
# to move the surplus to.
#
# Assumes backups live in subdirs of src and dst, named such that they sort in
# old-to-new order due to consistent timestamps in names, eg, under minters,
#     2020.09.06_02:37:01
#     2020.09.06_14:37:02
# For binder groups, we assume (sketchily) one binder per populator.
# Examples for the EZID binder group (under binders/ezid),
#     2020.09.07_00:47:16/egg_n2t_stg_public.real_ezid_s_ezid
#     2020.09.07_02:37:02/egg_n2t_stg_public.real_ezid_s_ezid
# and for the OCA binder group (under binders/oca),
#     2020.09.07_00:47:16/egg_n2t_stg_public.real_oca_s_oca
#     2020.09.07_02:37:02/egg_n2t_stg_public.real_oca_s_oca

# If 7th day, move 1 surplus backup to tier 2
# 	If 4x7th day, move 1 surplus tier 2 backup to tier 3
# 		Remove any surplus tier 3 backups
# 	Remove surplus tier 2 backups
# Remove surplus tier 1 backups

function surplus {

	local cmd=$1
	local src=$2
	local max=$3
	local dst=$4
	[[ $cmd == move1 || $cmd == remove ]] || {
		echo "error: command ($cmd) is not move1 or remove" 1>&2
		return
	}
	[[ $max =~ ^[0-9][0-9]*$ ]] || {
		echo "error: max ($max) is not an integer" 1>&2
		return
	}

	shopt -s nullglob
	# big assumption here that direct descendants are timestamped dirs
	local dirs=( $src/[12][0-9][0-9][0-9].??.??* )

	local surplus d
	let surplus=( ${#dirs[@]} - $max )
	#echo surplus $cmd $src $max $dst, excess is $surplus
	[[ $surplus -le 0 ]] &&
		return		# no surplus backups

	[[ $cmd == move1 ]] && {
		echo mv ${dirs[0]} $dst
		mv ${dirs[0]} $dst
		return
	}
	# else $cmd must be remove
	for d in ${dirs[@]}	# order is oldest first
	do
		echo rm $d
		rm -fr $d
		let surplus--
		[[ $surplus -le 0 ]] &&
			break
	done
}

# Strip surplus. Args say when and how many files to keep of each tier type.
#
# Usage: splus \
#	tier1 t1max t12cond \
#	tier2 t2max t23cond \
#	tier3 t3max
#
# Slightly complicated, but invocation serves as a kind of config file.
# Note: call with care as args are not checked for validity.
# Tier 1 backups are roughly "dailies".
# Tier 2 backups are roughly "weeklies".
# Tier 3 backups are roughly "monthlies".
#
# Example:  $ b=~/backups/binders/ezid
#	    $ splus	$b           10 $day7th \
#		        $b/weeklies  4  $day28th \
#		        $b/monthlies 4

function splus {

	local t1bax=$1		# tier1 backups directory
	local t1max=$2		# tier1 backups maximum number to keep
	local cond1to2=$3	# condition for moving from tier1 to tier2
	local t2bax=$4		# tier2 backups directory
	local t2max=$5		# tier2 backups maximum number to keep
	local cond2to3=$6	# condition for moving from tier2 to tier3
	local t3bax=$7		# tier3 backups directory
	local t3max=$8		# tier3 backups maximum number to keep

	if [[ $cond1to2 == 1 ]]		# eg, day of year is multiple of 7
	then
		mkdir -p $t2bax		# -p won't complain if exists already
		surplus move1 $t1bax $t1max $t2bax	# save oldest in tier2
		if [[ $cond2to3 == 1 ]]	# eg, day of year is multiple of 28
		then
			mkdir -p $t3bax
			surplus move1  $t2bax $t2max $t3bax	# save to tier3
			surplus remove $t3bax $t3max		# tier3 surplus
		fi
		surplus remove $t2bax $t2max			# tier2 surplus
	fi
	surplus remove $t1bax $t1max				# tier1 surplus
}

#  2  3  4  5  6  7  8 | 1
#  3  4  5  6  7  8  9 | 1 
#  4  5  6  7  8  9 10 | 1 
#  ...
#  7  8  9 10 11 12 13| 1 
#  8  9 10 11 12 13 14| 1 7
#  ...
# 14 15 16 17 18 19 20| 1 7
# 15 16 17 18 19 20 21| 1 7 14
#  ...
# 22 23 24 25 26 27 28| 1 7 14 21
# ...
# 29 30 31 32 33 34 35| 7 14 21 28| 1

function backup_rotate {

	# date +%j gives a 3-digit decimal number in the range 000-366.
	# We strip leading zeroes so that it won't be seen as octal.
	local dayofyear
	dayofyear=$( date "+%j" | sed 's/^00*//' )
	let day7th=( $dayofyear % 7 == 0 )	# is it a 7th day?
	let day28th=( $dayofyear % 28 == 0 )	# is it a 28th day?

	echo ==== rotating backups on day $dayofyear of year $(date) ====
	local bbk					# binders
	for bbk in ~/backups/binders/*		# $bbk is a populator name
	do
		#[[ $bbk =~ _test$ ]] &&
		#	continue	# test binder -- skip
		#[[ ! -e $apbinders/$( basename $bbk )/egg.bdb ]] &&
		#	continue	# not a binder -- skip
		# keep 14 dailies, 4 weeklies, 4 monthlies
		splus	$bbk           14 	$day7th \
		        $bbk/weeklies   4  	$day28th \
		        $bbk/monthlies  4
	done

	local mbk=~/backups/minters			# minters
	splus	$mbk           14 	$day7th \
		$mbk/weeklies   4  	$day28th \
		$mbk/monthlies  4

	local sbk=~/backups/shoulders			# shoulders
	splus	$sbk           14 	$day7th \
		$sbk/weeklies   4  	$day28th \
		$sbk/monthlies  4

	local pbk=~/backups/prefixes			# prefixes
	splus	$pbk           14 	$day7th \
		$pbk/weeklies   4  	$day28th \
		$pbk/monthlies  4
	return 0
}

function log_rotate {

	echo Not implemented yet.
	return 1
}

# (Re)Make ~/warts/env.yaml if it is out of date wrt ~/warts/env.sh.
# Setting bash vars in warts is convenient because you can use bash features
# to do things like variable substitution (eg, references to previously set
# values, tricky in YAML). But we want a YAML version of those settings
# because that conforms to Eggnog config file conventions.

function warts2yaml {

	local bashfile=$HOME/warts/env.sh
	local yamlfile=$HOME/warts/env.yaml

	[[ $yamlfile -nt $bashfile ]] && {
		echo Nothing to update
		return
	}

	# Temporarily put the perl script we'll use in the var $perl_warts,
	# using a "heredoc" (<<) so we don't have worry about quotes
	# surrounding it. Use the var right afterwards with perl -E.

	local perl_warts
	read -r -d '' perl_warts << 'EOT'
	# start embedded Perl program
	use strict;
	sub bash2yaml { my( $bashfile )=@_;
		my $environment = `bash -c "source $bashfile; env"`;
		map { /(^(?:EGNAPA|MG)_[^=]+)=(.*)/ and say "$1: \"$2\"" }
			split /\n/, $environment;
		return;
	}
	say '# File created by "admegn warts".';
	say '';
	foreach my $file (@ARGV) {
		bash2yaml($file);		# outputs to stdout
	}
	# end embedded Perl program
EOT

	# Now call the script just saved in $perl_warts, pass in values
	# via environment variables, and put file arguments on the end.

	env perl -E "$perl_warts" $bashfile > $yamlfile
	return
}

# MAIN

# Pick up whatever SVU mode may be in effect for the caller.

svumode=$( sed 's/^[^:]*://' <<< $SVU_USING )
[[ "$svumode" ]] ||
	svumode=cur		# if none, default to "cur"

eggnog=$HOME/sv/$svumode/build/eggnog
aptop=$HOME/sv/$svumode/apache2
apbinders=$aptop/binders
apminters=$aptop/minters

cmd=$1			# the first command word is the operation
shift			# $1 is now first command arg

verbose=
yes=
no_exec=
while [[ "$1" =~ ^- ]]	# $1 starts as the _second_ (post-command) arg
do
	case $1 in
	-v*|--v*)
		verbose=1
		shift
		;;
	-y)
		yes=1
		shift
		;;
	-n)
		no_exec=1
		shift
		;;
	*)
		echo "Error: unknown option: $1"
		usage
		exit 1
	esac
done

case $cmd in

help|"")
	usage
	exit
	;;
warts)
	warts2yaml $@
	exit
	;;
class)
	echo 'DEPRECATED: use "egg cfq class" instead'
	exit 1
	#class "$@"
	exit
	;;
binder_load)
	binder_load $@
	exit
	;;
msync)
	msync $@
	exit
	;;
bsync)
	bsync $@
	exit
	;;
bstat)
	bstat "$@"
	exit
	;;
mdump)
	mdump $@
	exit
	;;
mload)
	mload $@
	exit
	;;
cert_check)
	cert_check "$@"
	exit
	;;
validate_naans)
	validate_naans "$@"
	exit
	;;
rcheck)
	rcheck "$@"
	exit
	;;
rstat)
	rstat "$@"
	exit
	;;
bootwatch)
	[[ "$1" == "" ]] && {
		echo 'Error: missing Host argument for "$cmd"'
		exit 1
	}
	bootwatch $@
	exit
	;;
sysupdate)
	[[ $no_exec ]] && {
		echo 'Error: -n not yet supported for "$cmd"'
		exit 1
	}
	sysupdate $@
	exit
	;;
error_check)
	logfile=
	loglisting=
	for f in /var/log/kernel /var/log/system.log
	do
		[[ -e $f && -s $f ]] &&		# if a non-empty file exists
			loglisting+=$( ls -l $f )
		[[ -r $f && -s $f ]] &&	{	# file readable and non-empty?
			logfile=$f		# if so, we have a logfile
			break
		}
	done
	[[ ! "$loglisting" ]] &&		# if nothing to report
		exit 0				# just return
	linecount=$( wc -l $logfile | perl -pe 's/^\s*//; s/ .*//' )
	interesting=$( egrep -in 'segfault' $logfile )
	errors=$(
		echo $loglisting
		echo    "=== $linecount lines, cleared weekly ==="
		echo -n "1: "; head -1 $logfile
		echo -n "\$: "; tail -1 $logfile
		[[ "$interesting" ]] && {
			echo -n "=== possibly interesting lines ===" $'\n'
			echo "$interesting"
		}
		echo "=== last two reboots ==="
		last reboot | head -2 | perl -pe 's/(\d \d\d:\d\d).*/$1/'

		# That post-process step above removes variable, Linux-added
		# duration info for the "reboot" pseudo-login session.
	)
	perrs=~/.admegn_error_check
	[[ ! -e $perrs ]] &&		# if needed
		cp /dev/null $perrs	# initialize $perrs file
	terrs=$( mktemp /tmp/echeck.XXXX )	# temp file for current errors
	echo "$errors" > $terrs
	cmp -s $perrs $terrs &&		# if it's the same errors as previous
		if [[ "$verbose" ]];		# and if in verbose mode, then
		then
			errors='[no new errors]'$'\n'"$errors"	# annotate
		else
			errors=''		# else (not verbose) silence
		fi
	if [[ ! -z "$1" && ! -z "$errors" ]]
	then
		#class=$( admegn class )
		class=$( egg cfq class )	# xxx egg must be installed
		mail -s "$class system log messages" $1 <<< "$errors"
	elif [[ ! -z "$errors" ]]
	then
		echo "$errors"
	fi
	mv $terrs $perrs		# make current the new previous errors
	exit
	;;
patch_check)
	patches=$( yum updateinfo list | grep -i critical )
	[[ -z "$patches" ]] &&
		exit
	if [[ ! -z "$1" ]]
	then
		mail -s "critical patches pending" $1 <<< "$patches"
	else
		echo "$patches"
	fi
	exit
	;;
pingwhen)
	grep 'GET / HTTP' $( mrm $aptop/logs/access_log ) | tail -15
	echo -n 'Current time: '
	date
	exit
	;;
logdelete)
	[[ $no_exec ]] && {
		echo 'Error: aborting: -n not supported for "$cmd"'
		exit 1
	}
	logdelete $@
	exit
	;;
logscrub)
	[[ $no_exec ]] && {
		echo 'Error: aborting: -n not supported for "$cmd"'
		exit 1
	}
	# non = non-anonymized
	perl -pi.nnon -e 's/(?:\d+\.){3}\d+ /12.34.56.78 /g' "$@" || {
		echo Error: problem anonymizing Apache log file
		exit 1
	}
	exit
	;;
logrename)
	logrename "$@"
	exit
	;;
backup)
	[[ $no_exec ]] && {
		echo 'Error: -n not yet supported for "$cmd"'
		exit 1
	}
	backup $@
	exit
	;;
backup_rotate)
	[[ $no_exec ]] && {
		echo 'Error: -n not yet supported for "$cmd"'
		exit 1
	}
	backup_rotate $@
	exit
	;;
mmigrate)
	#[[ $1 == migrate ]]
	;;
-*)
	echo "Error: options go after the subcommand"
	exit 1
	;;

*)
	echo "Error: unknown subcommand: $cmd"
	exit 1
	;;
esac

